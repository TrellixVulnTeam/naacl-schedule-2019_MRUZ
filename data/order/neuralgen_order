* Thursday, June 6, 2019
+ 9:00--9:10 Opening Remarks
+ 9:10--9:45 Invited Talk: Kyunghyun Cho
+ 9:45--10:20 Invited Talk: He He
+ 10:20--10:35 Coffee Break
+ 10:35--11:10 Invited Talk: Graham Neubig
+ 11:10--11:45 Invited Talk: Yejin Choi
+ 11:45--13:15 Lunch
+ 13:15--13:50 Invited Talk: Alexander Rush
+ 13:50--14:15 Spotlight Talks
+ 14:15--15:45 Poster Session
6   # An Adversarial Learning Framework For A Persona-Based Multi-Turn Dialogue Model
7   # DAL: Dual Adversarial Learning for Dialogue Generation
10   # Towards Coherent and Engaging Spoken Dialog Response Generation Using Automatic Conversation Evaluators
11   # How to Compare Summarizers without Target Length? Pitfalls, Solutions and Re-Examination of the Neural Summarization Literature
13   # BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model
15   # Neural Text Simplification in Low-Resource Conditions Using Weak Supervision
16   # Paraphrase Generation for Semi-Supervised Learning in NLU
19   # Bilingual-GAN: A Step Towards Parallel Text Generation
24   # Learning Criteria and Evaluation Metrics for Textual Transfer between Non-Parallel Corpora
28   # Dual Supervised Learning for Natural Language Understanding and Generation
30   # Designing a Symbolic Intermediate Representation for Neural Surface Realization
31   # Insertion-based Decoding with automatically Inferred Generation Order
34   # Neural Text Style Transfer via Denoising and Reranking
36   # Generating Diverse Story Continuations with Controllable Semantics
38   # Better Automatic Evaluation of Open-Domain Dialogue Systems with Contextualized Embeddings
40   # Improved Zero-shot Neural Machine Translation via Ignoring Spurious Correlations
42   # Jointly Measuring Diversity and Quality in Text Generation Models
+ 15:45--16:20 Invited Talk: Tatsunori Hashimoto
+ 16:20--16:55 Invited Talk: Hal Daum√© III
+ 16:55--17:55 Panel
+ 17:55--18:00 Closing Remarks